{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 100 - LinearRegression & GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The load_boston() function from the scikit-learn package was used to load the data into the raw_data variable. Then, based on the 'data' and 'target' keys of the raw_data object, the df DataFrame was prepared as shown below: <br>\n",
    "<br>\n",
    "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO       B  LSTAT  target <br>\n",
    "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0     15.3  396.90   4.98    24.0 <br>\n",
    "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8  396.90   9.14    21.6 <br>\n",
    "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8  392.83   4.03    34.7 <br>\n",
    "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7  394.63   2.94    33.4 <br>\n",
    "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7  396.90   5.33    36.2 <br>\n",
    "<br>\n",
    "The df object was copied to the data variable. Then the target column was popped out from the data object and assigned to the target variable. <br>\n",
    "Using the train_test_split() function, the data (data, target) was splitted into train and test sets and assigned to the variables: <br>\n",
    "<br>\n",
    "data_train, target_train <br>\n",
    "data_test, target_test <br>\n",
    "<br>\n",
    "The LinearRegression class from the scikit-learn package was used to create a linear regression model. The model was fitted on the training data. Make predictions based on the model on the test data and assign the result to target_pred variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.83885359 36.00783288 15.08324755 25.23090886 18.87864064 23.21398327\n",
      " 17.5931124  14.30508093 23.05438985 20.62008346 24.78514683 18.66833668\n",
      " -6.9788951  21.83575737 19.20898992 26.2868054  20.54379176  5.65713224\n",
      " 40.42358065 17.64146116 27.32258958 30.05056174 11.15013704 24.11530393\n",
      " 17.89145648 15.79348591 22.94743453 14.2586068  22.26731194 19.24709013\n",
      " 22.26897546 25.24344002 25.69165643 17.98759507 16.70286649 17.11631225\n",
      " 31.19643534 20.17835831 23.71828436 24.79196868 13.94575895 32.00389982\n",
      " 42.53869791 17.44523722 27.15354457 17.07482215 13.89272021 26.06440323\n",
      " 20.36888769 29.97813037 21.35346608 34.32287916 15.88498671 26.17757739\n",
      " 39.50970314 22.84123308 18.95049088 32.68913818 25.02057949 12.90539147\n",
      " 22.76052302 30.53884316 31.60797905 15.92162168 20.50670563 16.50798147\n",
      " 20.50202198 26.00723901 30.63860954 11.42877835 20.53765181 27.56249175\n",
      " 10.85162601 15.96871769 23.87570192  5.66369672 21.47818991 41.2820034\n",
      " 18.56559986  9.08857252 20.97848452 13.0630057  20.99054395  9.34050291\n",
      " 23.13686588 31.80106627 19.10245917 25.59186169 29.14490119 20.17571514\n",
      " 25.5962149   5.20301905 20.16835681 15.08546746 12.8601543  20.80904894\n",
      " 24.68556943 -0.77450939 13.33875673 15.62703156 22.21755358 24.58188737\n",
      " 10.77302163 19.50068376 23.23450396 11.77388822 18.36777924 25.4383785\n",
      " 20.89079232 24.08440617  7.3658717  19.16424347 21.93734133 27.41191713\n",
      " 32.50857196 14.86885244 35.05912525 12.86075113 20.83043572 28.42077138\n",
      " 15.65853688 24.67196362  3.28420892 23.79879617 25.73329894 23.04815612\n",
      " 24.73046824]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "raw_data = load_boston()\n",
    " \n",
    "df = pd.DataFrame(\n",
    "    data=np.c_[raw_data.data, raw_data.target],\n",
    "    columns=list(raw_data.feature_names) + ['target'],\n",
    ")\n",
    "data = df.copy()\n",
    "target = data.pop('target')\n",
    "(\n",
    "    data_train,\n",
    "    data_test,\n",
    "    target_train,\n",
    "    target_test,\n",
    ") = train_test_split(data, target, random_state=42)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(data_train, target_train)\n",
    " \n",
    "target_pred = regressor.predict(data_test)\n",
    "print(target_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The load_boston() function from the scikit-learn package was used to load the data into the raw_data variable. Then, based on the 'data' and 'target' keys of the raw_data object, the df DataFrame was prepared as shown below: <br>\n",
    "<br>\n",
    "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO       B  LSTAT  target <br>\n",
    "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0     15.3  396.90   4.98    24.0 <br>\n",
    "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8  396.90   9.14    21.6 <br>\n",
    "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8  392.83   4.03    34.7 <br>\n",
    "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7  394.63   2.94    33.4 <br>\n",
    "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7  396.90   5.33    36.2 <br>\n",
    "<br>\n",
    "The df object was copied to the data variable. Then the target column was popped out from the data object and assigned to the target variable. <br>\n",
    "Using the train_test_split() function, the data (data, target) was splitted into train and test sets and assigned to the variables: <br>\n",
    "<br>\n",
    "data_train, target_train <br>\n",
    "data_test, target_test <br>\n",
    "<br>\n",
    "The LinearRegression class from the scikit-learn package was used to create a linear regression model. The model was fitted on the training data. Model-based predictions were made on the test data and the result was assigned to the target_pred variable. Create a new DataFrame object named predictions that will have four columns: <br>\n",
    "<br>\n",
    "target_test <br>\n",
    "target_pred <br>\n",
    "<br>\n",
    "error (the difference between target_pred and target_test) <br>\n",
    "abs_error (the absolute value of the error column) <br>\n",
    "In response, print the first ten rows of the predictions DataFrame to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target_test  target_pred     error  abs_error\n",
      "0         23.6    28.838854  5.238854   5.238854\n",
      "1         32.4    36.007833  3.607833   3.607833\n",
      "2         13.6    15.083248  1.483248   1.483248\n",
      "3         22.8    25.230909  2.430909   2.430909\n",
      "4         16.1    18.878641  2.778641   2.778641\n",
      "5         20.0    23.213983  3.213983   3.213983\n",
      "6         17.8    17.593112 -0.206888   0.206888\n",
      "7         14.0    14.305081  0.305081   0.305081\n",
      "8         19.6    23.054390  3.454390   3.454390\n",
      "9         16.8    20.620083  3.820083   3.820083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    " \n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "raw_data = load_boston()\n",
    " \n",
    "df = pd.DataFrame(\n",
    "    data=np.c_[raw_data.data, raw_data.target],\n",
    "    columns=list(raw_data.feature_names) + ['target'],\n",
    ")\n",
    "data = df.copy()\n",
    "target = data.pop('target')\n",
    "(\n",
    "    data_train,\n",
    "    data_test,\n",
    "    target_train,\n",
    "    target_test,\n",
    ") = train_test_split(data, target, random_state=42)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(data_train, target_train)\n",
    "target_pred = regressor.predict(data_test)\n",
    " \n",
    "predictions = pd.DataFrame(\n",
    "    np.c_[target_test, target_pred],\n",
    "    columns=['target_test', 'target_pred'],\n",
    ")\n",
    "predictions['error'] = (\n",
    "    predictions['target_pred'] - predictions['target_test']\n",
    ")\n",
    "predictions['abs_error'] = abs(predictions['error'])\n",
    "print(predictions.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The load_boston() function from the scikit-learn package was used to load the data into the raw_data variable. Then, based on the 'data' and 'target' keys of the raw_data object, the df DataFrame was prepared as shown below: <br>\n",
    "<br>\n",
    "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO       B  LSTAT  target <br> \n",
    "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0     15.3  396.90   4.98    24.0 <br>\n",
    "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8  396.90   9.14    21.6 <br>\n",
    "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8  392.83   4.03    34.7 <br>\n",
    "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7  394.63   2.94    33.4 <br>\n",
    "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7  396.90   5.33    36.2 <br>\n",
    "<br>\n",
    "The df object was copied to the data variable. Then the target column was popped out from the data object and assigned to the target variable. <br>\n",
    "Using the train_test_split() function, the data (data, target) was splitted into train and test sets and assigned to the variable <br>\n",
    "<br>\n",
    "data_train, target_train <br>\n",
    "data_test, target_test <br>\n",
    "<br>\n",
    "Use the GradientBoostingRegressor class (with the parameter random_state=42) from the scikit-learn package to create a regression model. Fit the model on the train data and evaluate on the test data. In response, print R^2 score of this model to the console as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor()\n",
      "R^2 score: 0.8736\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, random_state=42)\n",
    "\n",
    "regressor = GradientBoostingRegressor()\n",
    "regressor.fit(data_train, target_train)\n",
    "\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(regressor, file)\n",
    "\n",
    "with open('model.pkl', 'rb') as file:\n",
    "    regressor_loaded = pickle.load(file)\n",
    "\n",
    "\n",
    "predictions = regressor_loaded.predict(data_test)\n",
    "r2 = r2_score(target_test, predictions)\n",
    "print(f\"R^2 score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
