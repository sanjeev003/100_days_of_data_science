{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 80 - train-test split, logistic regression & prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The IRIS dataset was loaded into data and target variables. <br>\n",
    "Using the scikit-learn package and the train_test_split() function, split the data into the training set (data_train, target_train) and the test set (data_test, target_test). Set the test size to 30% of the samples. <br>\n",
    "As an answer, print the shapes of the following arrays:\n",
    "<br>\n",
    "data_train<br>\n",
    "target_train<br>\n",
    "data_test<br>\n",
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train shape: (105, 4)\n",
      "target_train shape: (105,)\n",
      "data_test shape: (45, 4)\n",
      "target_test shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_raw = load_iris()\n",
    "data = data_raw['data']\n",
    "target = data_raw['target']\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.3\n",
    ")\n",
    "print(f'data_train shape: {data_train.shape}')\n",
    "print(f'target_train shape: {target_train.shape}')\n",
    "print(f'data_test shape: {data_test.shape}')\n",
    "print(f'target_test shape: {target_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The IRIS dataset was loaded into data and target variables. These datasets was spitted into the training set (data_train, target_train) and the test set (data_test, target_test). <br>\n",
    "Create a logistic regression model (set max_iter=1000) using the scikit-learn package. Fit the model on the train set and then evaluate the model on the test set. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "data_raw = load_iris()\n",
    "data = data_raw['data']\n",
    "target = data_raw['target']\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.3, random_state=20\n",
    ")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(data_train, target_train)\n",
    "accuracy = model.score(data_test, target_test)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The IRIS dataset was loaded into data and target variables. These datasets was spitted into the training set (data_train, target_train) and the test set (data_test, target_test). <br>\n",
    "The logistic regression model was built using the scikit-learn package. <br>\n",
    "Using this model make a prediction on the test set and assign to target_pred variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 2 1 1 2 0 2 0 2 1 1 0 0 2 0 1 2 1 1 2 2 0 1 1 1 0 2 1 1 1 0 0 0 1 1\n",
      " 0 1 2 1 2 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data_raw = load_iris()\n",
    "data = data_raw['data']\n",
    "target = data_raw['target']\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.3, random_state=20\n",
    ")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(data_train, target_train)\n",
    "target_pred = model.predict(data_test)\n",
    "print(target_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The IRIS dataset was loaded into data and target variables. These datasets was spitted into the training set (data_train, target_train) and the test set (data_test, target_test). The logistic regression model was built using the scikit-learn package. <br>\n",
    "Predictions on the test set was assigned to the variable target_pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  3 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix \n",
    " \n",
    "data_raw = load_iris()\n",
    "data = data_raw['data']\n",
    "target = data_raw['target']\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.3, random_state=20\n",
    ")\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(data_train, target_train)\n",
    "target_pred = model.predict(data_test)\n",
    "cm = confusion_matrix(target_test, target_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
