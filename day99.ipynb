{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 99 - LinearRegression & R^2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The load_boston() function from the scikit-learn package was used to load the data into the raw_data variable. Then, based on the 'data' and 'target' keys of the raw_data object, the df DataFrame was prepared as shown below: <br>\n",
    "<br>\n",
    "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO       B  LSTAT  target <br>\n",
    "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0     15.3  396.90   4.98    24.0 <br>\n",
    "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8  396.90   9.14    21.6 <br>\n",
    "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8  392.83   4.03    34.7 <br>\n",
    "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7  394.63   2.94    33.4 <br>\n",
    "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7  396.90   5.33    36.2 <br>\n",
    "<br>\n",
    "The df object was copied to the data variable. Then the target column was popped out from the data object and assigned to the target variable. <br>\n",
    "Using the train_test_split() function, split the data (data, target) into train and test sets (use the parameter random_datate=42) and assign to the following variables: <br>\n",
    "<br>\n",
    "data_train, target_train <br>\n",
    "data_test, target_test <br>\n",
    "<br>\n",
    "In response, print the shapes of the following objects: data_train, target_train, data_test, target_test <br>\n",
    "<br>\n",
    "Expected result: <br>\n",
    "<br>\n",
    "data_train shape: (379, 13) <br>\n",
    "target_train shape: (379,) <br>\n",
    "data_test shape: (127, 13) <br>\n",
    "target_test shape: (127,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train shape: (379, 13)\n",
      "target_train shape: (379,)\n",
      "data_test shape: (127, 13)\n",
      "target_test shape: (127,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    " \n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 150)\n",
    "raw_data = load_boston()\n",
    " \n",
    "df = pd.DataFrame(\n",
    "    data=np.c_[raw_data.data, raw_data.target],\n",
    "    columns=list(raw_data.feature_names) + ['target'],\n",
    ")\n",
    " \n",
    "data = df.copy()\n",
    "target = data.pop('target')\n",
    " \n",
    "(\n",
    "    data_train,\n",
    "    data_test,\n",
    "    target_train,\n",
    "    target_test,\n",
    ") = train_test_split(data, target, random_state=42)\n",
    " \n",
    "print(f'data_train shape: {data_train.shape}')\n",
    "print(f'target_train shape: {target_train.shape}')\n",
    "print(f'data_test shape: {data_test.shape}')\n",
    "print(f'target_test shape: {target_test.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
